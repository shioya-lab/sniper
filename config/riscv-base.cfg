# Updated to reflect Golden Cove according to:
# https://chipsandcheese.com/2021/12/02/popping-the-hood-on-golden-cove/
# The page says:
# > Some of the our data comes from Intel’s Architecture Day presentation. The
# > rest comes from our own testing on an i9-12900K. We don’t have a board that
# > allows AVX-512 instructions, and those instructions fault on Golden Cove, so
# > unfortunately that won’t be covered. And of course, treat this diagram as a
# > rough approximation, because testing is hard.
#
# [perf_model/core]
# frequency
#
# [perf_model/core/rob_timer]
# commit_width, outstanding_loads, outstanding_stores, rs_entries,
# alu_rs_entries, lu_rs_entries, su_rs_entries
#
# [perf_model/core/interval_timer]
# dispatch_width, window_size, num_outstanding_loadstores
#
# [perf_model/cache]
# levels
#
# [perf_model/itlb]
# size, associativity
#
# [perf_model/dtlb]
# size
#
# [perf_model/stlb]
# size
#
# [perf_model/l1_icache]
# next_level_read_bandwidth
#
# [perf_model/l1_dcache]
# cache_size, associativity, data_access_time, outstanding_misses,
# next_level_read_bandwidth
#
# [perf_model/l2_cache]
# cache_size, data_access_time, next_level_read_bandwidth
#
# [perf_model/l3_cache]
# cache_size, data_access_time
#
# [perf_model/dram]
# latency, per_controller_bandwidth

[general]
arch = riscv
enable_icache_modeling = true
mode = 64
syntax = default
magic = true
konata_count_max = 1000000
#total_cores = 2

[perf_model/core]
core_model = riscv
frequency = 5
type = rob # or interval
logical_cpus = 1 # Number of SMT threads per core

[perf_model/core/rob_timer]   # https://github.com/riscv-boom/riscv-boom/blob/1a153d4974977a2d5f8baa9b4de51b3337d230fe/src/main/scala/common/config-mixins.scala
address_disambiguation = true  # Allow loads to bypass preceding stores with an unknown address
commit_width = 8                      # Commit bandwidth (instructions per cycle), per SMT thread
issue_contention = true
issue_memops_at_issue = true  # Issue memops to the memory hierarchy at issue time (false = before dispatch)
mlp_histogram = false
outstanding_loads = 192
outstanding_stores = 114
outstanding_vec_loads = 0
outstanding_vec_stores = 0
rob_repartition = true
rs_entries = 205
alu_rs_entries = 97
lu_rs_entries = 70
su_rs_entries = 38
simultaneous_issue = true
store_to_load_forwarding = true
gather_scatter_merge = true

[perf_model/core/interval_timer]
dispatch_width = 6
window_size = 512
num_outstanding_loadstores = 306

[perf_model/core/static_instruction_costs]
add = 1
sub = 1
mul = 3
div = 12  # 4-12 Word, 4-20 64-bit
fadd = 4
fsub = 4
fmul = 4
fdiv = 11  # 6-11 s form, 6-18 d form
generic = 1
jmp = 1
string = 1
branch = 1
dynamic_misc = 1
recv = 1
sync = 0
spawn = 0
tlb_miss = 0
mem_access = 0
delay = 0
unknown = 0

[perf_model/branch_predictor]
type = tage_sc_l_64kb
mispredict_penalty = 15

#https://github.com/riscv-boom/riscv-boom/blob/1a153d4974977a2d5f8baa9b4de51b3337d230fe/src/main/scala/common/config-mixins.scala
[perf_model/cache]
levels = 3

[perf_model/tlb]
penalty = 30   # "variable number of cycles"

[perf_model/itlb]
size = 256 # Number of I-TLB entries
associativity = 8

[perf_model/dtlb]
size = 64 # Number of D-TLB entries
associativity = 32

[perf_model/stlb]
size = 2048 # Number of second-level TLB entries
associativity = 1 # S-TLB associativity

[perf_model/l1_icache]
cache_block_size = 64 # in B
cache_size = 32 # in KB
associativity = 8
replacement_policy = lru
writethrough = 0
perfect = false
passthrough = false
coherent = true
data_access_time = 3
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0    # Extra time required to write back data to a higher cache level
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
next_level_read_bandwidth = 128 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite
prefetcher = simple
address_hash = mask

[perf_model/l1_icache/prefetcher]
prefetch_on_prefetch_hit = false
train_prefetcher_on_hit = false
delay_prefetcher = false

[perf_model/l1_icache/prefetcher/simple]
flows = 8
flows_per_core = false
num_prefetches = 32
stop_at_page_boundary = true


[perf_model/l1_dcache]
cache_block_size = 64
num_banks = 1
cache_size = 48 # in KB
associativity = 12
replacement_policy = lru
prefetcher = simple  #simple  #??
writethrough = 0
perfect = false
passthrough = false
address_hash = mod
data_access_time = 5
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0    # Extra time required to write back data to a higher cache level
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
outstanding_misses = 16
next_level_read_bandwidth = 512 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite

[perf_model/l1_dcache/prefetcher]
prefetch_on_prefetch_hit = false
train_prefetcher_on_hit = false
delay_prefetcher = false

[perf_model/l1_dcache/prefetcher/simple]
flows = 8
flows_per_core = false
num_prefetches = 64
stop_at_page_boundary = true

[perf_model/l2_cache]
cache_block_size = 64 # in bytes
cache_size = 1280 # in KB
associativity = 16
replacement_policy = lru
data_access_time = 14
tags_access_time = 5 # Maximum from the overall RAM latency calculation table, tech ref manual
writeback_time = 2 # approx of 1.5 ns; 3 cycles at 2 GHz; Extra time required to write back data to a higher cache level
prefetcher = simple # optional
next_level_read_bandwidth = 256 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite
writethrough = 0
perfect = false
passthrough = false
address_hash = mod
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
perf_model_type = parallel

[perf_model/l2_cache/prefetcher]
prefetch_on_prefetch_hit = false

[perf_model/l2_cache/prefetcher/simple]
flows = 64
flows_per_core = true
num_prefetches = 128
stop_at_page_boundary = true

[perf_model/l3_cache]
perfect = false
cache_block_size = 64
cache_size = 30720
associativity = 16
replacement_policy = lru
address_hash = mod
dvfs_domain = global  # Clock domain: core or global
prefetcher = none
data_access_time = 74
tags_access_time = 10
writeback_time = 0    # Extra time required to write back data to a higher cache level
shared_cores = 1      # Number of cores sharing this cache
perf_model_type = parallel
writethrough = 0

[perf_model/llc]
evict_buffers = 48

[caching_protocol]
type = parametric_dram_directory_msi
variant = mesi # msi, mesi or mesif

[perf_model/dram_directory]
total_entries = 16384
associativity = 16
directory_type = full_map # Supported (full_map, limited_no_broadcast, limitless)

[perf_model/dram]
type = constant # DRAM performance model type: "constant" or a "normal" distribution
latency = 84    # In nanoseconds
per_controller_bandwidth = 32 # In GB/s
num_controllers = -1 # Total Bandwidth = per_controller_bandwidth * num_controllers
controllers_interleaving = 1 # If num_controllers == -1, place a DRAM controller every N cores
chips_per_dimm = 8
dimms_per_controller = 4
controller_positions = ""
direct_access = true                     # Access DRAM controller directly from last-level cache (only when there is a single LLC)


[perf_model/sync]
reschedule_cost = 0 # In nanoseconds

[network/bus]
ignore_local_traffic = true # Do not count traffic between core and directory on the same tile
bandwidth = 25.6 # in GB/s. Actually, it's 12.8 GB/s per direction and per connected chip pair

[dvfs]
type = simple
transition_latency = 0 # In nanoseconds
